{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Regularized Iterative Soft Thresholding Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The BARISTA algorithm is a class-specific attribute weighted Naive Bayes framework designed to mitigate overfitting and alleviating the condition independence assumption of Naive Bayes. This is a brief tutorial on running the model.\n",
    "\n",
    "**Data Importing**\n",
    "\n",
    "Please upload your data from a csv file into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "breast_w = pd.read_csv('/filepath/breast_w.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**\n",
    "\n",
    "Missing values are imputed with the mean value or max frequency depending on the attribute type. Numerical attributes are discretized using the MDL discretization technique (see our paper for details). Pass in the dataset, the target attribute column name as a string, and a list of attribute column names that are numerical; in this case there are none). Next, use the get_data function to get a design matrix, $X$ and a vector of labels, $y$. Finally, we split the data in a testing set and a training set to evaluate generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "breast_w = preprocess.Preprocess(breast_w, \"Class\", [])\n",
    "X, y = breast_w.get_data()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "X_train = X_train.reset_index(drop = True)\n",
    "y_train = y_train.reset_index(drop = True)\n",
    "X_test = X_test.reset_index(drop = True)\n",
    "y_test = y_test.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitting the Data**\n",
    "\n",
    "We can now fit the training data using the BARISTA algorithm. Once the fit method is used, the optimization procedure will be used. For parameter details, see the readMe file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Model Parameters...\n",
      "Prior Probability Distribution Computed...\n",
      "Prior Probability Distribution Computed...\n",
      "Initial Posterior Probability Distribution Computed...\n",
      "FISTA Scheme Selected (Default)\n",
      "__Optimizing__...\n",
      "Initial Loss: 134.02415441350448\n",
      "Iteration: 1\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999728938206, 2.710617945104171e-08]\n",
      "\n",
      "Weight Matrix: [[0.9940581  0.9901933  0.99001009 0.99130065 0.99034259 0.99393587\n",
      "  0.992734   0.98944736 0.99731843]\n",
      " [1.00329713 1.00258097 1.00213735 1.00354258 1.00227644 1.003067\n",
      "  1.00183815 1.00395688 1.00032793]]\n",
      "\n",
      "Gradient Norm: 0.24483661379631588\n",
      "\n",
      "Gradient Matrix: [[ 0.04941899  0.08806701  0.08989906  0.07699352  0.08657407  0.05064131\n",
      "   0.06266002  0.09552644  0.01681571]\n",
      " [-0.04297135 -0.03580969 -0.03137351 -0.04542576 -0.03276444 -0.04066996\n",
      "  -0.02838146 -0.04956877 -0.01327929]]\n",
      "\n",
      "Model Loss: 130.80171125513738\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 2\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999773437669, 2.2656233124745668e-08]\n",
      "\n",
      "Weight Matrix: [[0.98828208 0.98049864 0.98012021 0.98267598 0.98076931 0.98806435\n",
      "  0.98556738 0.97896079 0.99468668]\n",
      " [1.00650688 1.00505093 1.00413986 1.00699563 1.00446945 1.00599528\n",
      "  1.00355852 1.00783074 1.00061202]]\n",
      "\n",
      "Gradient Norm: 0.2409415811965605\n",
      "\n",
      "Gradient Matrix: [[ 0.04776025  0.08694662  0.08889885  0.07624669  0.08573279  0.04871517\n",
      "   0.06166617  0.09486561  0.0163175 ]\n",
      " [-0.04209742 -0.0346996  -0.03002512 -0.0445305  -0.03193003 -0.03928281\n",
      "  -0.02720377 -0.04873865 -0.0128409 ]]\n",
      "\n",
      "Model Loss: 127.67835336388691\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 3\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.999999981901342, 1.809865798591692e-08]\n",
      "\n",
      "Weight Matrix: [[0.9810453  0.9681888  0.96754792 0.97170452 0.96858622 0.98073433\n",
      "  0.97648496 0.96559668 0.99136172]\n",
      " [1.01053029 1.00810347 1.00656987 1.01132905 1.00719475 1.00960685\n",
      "  1.00564434 1.01271004 1.00093244]]\n",
      "\n",
      "Gradient Norm: 0.23690877231191973\n",
      "\n",
      "Gradient Matrix: [[ 0.04609361  0.08578337  0.08785777  0.07541429  0.0848579   0.04675706\n",
      "   0.06063197  0.09409485  0.01583456]\n",
      " [-0.0411906  -0.0335662  -0.02865796 -0.04360517 -0.03107412 -0.03786519\n",
      "  -0.02601091 -0.0478782  -0.01240376]]\n",
      "\n",
      "Model Loss: 123.80021721443485\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 4\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999861090008, 1.3890999252718717e-08]\n",
      "\n",
      "Weight Matrix: [[0.97250989 0.95342422 0.95244637 0.9585216  0.95393142 0.97213358\n",
      "  0.96561988 0.94950291 0.98739363]\n",
      " [1.01527298 1.01163436 1.00931061 1.01644602 1.01037078 1.01377301\n",
      "  1.00799447 1.01849941 1.00125599]]\n",
      "\n",
      "Gradient Norm: 0.23148525862808458\n",
      "\n",
      "Gradient Matrix: [[ 0.04394334  0.08421579  0.0864464   0.07420841  0.08366813  0.044192\n",
      "   0.05922925  0.09293178  0.01524911]\n",
      " [-0.03996351 -0.03205956 -0.02686002 -0.04236073 -0.02993139 -0.03598582\n",
      "  -0.02444803 -0.0467155  -0.01184473]]\n",
      "\n",
      "Model Loss: 119.28670079886396\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 5\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999896971106, 1.0302889483248649e-08]\n",
      "\n",
      "Weight Matrix: [[0.9628451  0.93636546 0.93496775 0.94326822 0.93693982 0.96246582\n",
      "  0.95311123 0.93083292 0.98282555]\n",
      " [1.02062799 1.01552277 1.01222642 1.02223848 1.01390375 1.0183457\n",
      "  1.01049246 1.02509387 1.00154512]]\n",
      "\n",
      "Gradient Norm: 0.2244634965855384\n",
      "\n",
      "Gradient Matrix: [[ 0.04131951  0.08217826  0.08458732  0.07252405  0.08208964  0.04100216\n",
      "   0.05738599  0.09123167  0.01460774]\n",
      " [-0.03836348 -0.03013284 -0.02460315 -0.04075031 -0.02846286 -0.03360191\n",
      "  -0.02249912 -0.04519937 -0.01117305]]\n",
      "\n",
      "Model Loss: 114.27451749148058\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 6\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999925661107, 7.433889186199132e-09]\n",
      "\n",
      "Weight Matrix: [[0.95223602 0.91719267 0.91528563 0.92610821 0.91776377 0.95196015\n",
      "  0.93912073 0.90977122 0.97769349]\n",
      " [1.02646769 1.01962299 1.01515829 1.0285785  1.01768049 1.02314972\n",
      "  1.01300281 1.03236908 1.00175814]]\n",
      "\n",
      "Gradient Norm: 0.2155849885273097\n",
      "\n",
      "Gradient Matrix: [[ 0.03822004  0.07958367  0.08216298  0.07026607  0.08001855  0.03716828\n",
      "   0.05500587  0.08882517  0.01396796]\n",
      " [-0.0363323  -0.02771923 -0.02185933 -0.03871609 -0.0266128  -0.03065994\n",
      "  -0.02014615 -0.04326584 -0.010399  ]]\n",
      "\n",
      "Model Loss: 108.9239188977293\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 7\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999947414914, 5.258508697415129e-09]\n",
      "\n",
      "Weight Matrix: [[0.9408903  0.8961174  0.89361192 0.90723181 0.89658711 0.94087427\n",
      "  0.92384283 0.88654903 0.97202498]\n",
      " [1.03264037 1.02375801 1.01792306 1.03531312 1.02156282 1.02797845\n",
      "  1.01536981 1.04017557 1.00184935]]\n",
      "\n",
      "Gradient Norm: 0.20460643793927383\n",
      "\n",
      "Gradient Matrix: [[ 0.03461247  0.0763361   0.07901527  0.06740877  0.07732867  0.03268498\n",
      "   0.05199134  0.08554756  0.01338195]\n",
      " [-0.0338316  -0.02474293 -0.0186222  -0.03620439 -0.02431512 -0.02711291\n",
      "  -0.01737972 -0.04085442 -0.00952973]]\n",
      "\n",
      "Model Loss: 103.41910730298659\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 8\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999963206252, 3.6793749082155353e-09]\n",
      "\n",
      "Weight Matrix: [[0.9290478  0.8733927  0.87021478 0.88684867 0.87364026 0.92949385\n",
      "  0.90751113 0.86145628 0.96583926]\n",
      " [1.03896968 1.02771366 1.02031466 1.04226078 1.02538177 1.03259147\n",
      "  1.01741722 1.04833481 1.00176818]]\n",
      "\n",
      "Gradient Norm: 0.1913062041940488\n",
      "\n",
      "Gradient Matrix: [[ 0.03040662  0.07232372  0.07493302  0.06402862  0.07384804  0.02757264\n",
      "   0.04825926  0.08124104  0.0128779 ]\n",
      " [-0.03084692 -0.02112223 -0.01490419 -0.03316622 -0.02149282 -0.02292567\n",
      "  -0.01419756 -0.03791131 -0.00856108]]\n",
      "\n",
      "Model Loss: 97.96696066437143\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 9\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.999999997426926, 2.5730740028722793e-09]\n",
      "\n",
      "Weight Matrix: [[0.91699647 0.8493281  0.84544197 0.8651791  0.84922412 0.91813141\n",
      "  0.89040589 0.8348569  0.95914979]\n",
      " [1.04525103 1.03123043 1.02210112 1.04920497 1.02892951 1.03671034\n",
      "  1.01894517 1.0566332  1.00145644]]\n",
      "\n",
      "Gradient Norm: 0.17535249401656908\n",
      "\n",
      "Gradient Matrix: [[ 0.02542488  0.06736899  0.0696196   0.06024281  0.0692884   0.02185609\n",
      "   0.04370903  0.0757025   0.01245033]\n",
      " [-0.02733745 -0.01674634 -0.01068089 -0.02952308 -0.01803835 -0.01804405\n",
      "  -0.01056884 -0.03435981 -0.00746585]]\n",
      "\n",
      "Model Loss: 92.7986676686709\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 10\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999981792007, 1.8207992323177283e-09]\n",
      "\n",
      "Weight Matrix: [[0.90509234 0.82431229 0.81974865 0.84245777 0.82374332 0.90713179\n",
      "  0.87286854 0.807211   0.95196873]\n",
      " [1.05123958 1.03399082 1.02301301 1.05588265 1.0319479  1.04000939\n",
      "  1.01972024 1.06481161 1.00084336]]\n",
      "\n",
      "Gradient Norm: 0.1562271634488555\n",
      "\n",
      "Gradient Matrix: [[ 0.0194167   0.06119193  0.06270011  0.05605871  0.06322725  0.01549469\n",
      "   0.03816343  0.06864176  0.0120616 ]\n",
      " [-0.02317168 -0.01144996 -0.00583318 -0.02513341 -0.01379958 -0.0123589\n",
      "  -0.00638749 -0.0300698  -0.00618753]]\n",
      "\n",
      "Model Loss: 88.16670838346135\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 11\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999986765704, 1.3234295619384526e-09]\n",
      "\n",
      "Weight Matrix: [[0.89377044 0.79883285 0.79371364 0.81895848 0.79772939 0.89688843\n",
      "  0.855318   0.77909279 0.94431281]\n",
      " [1.05663435 1.03560827 1.02272976 1.06197323 1.03411954 1.04210815\n",
      "  1.01946295 1.07255573 0.99984023]]\n",
      "\n",
      "Gradient Norm: 0.13366223826063692\n",
      "\n",
      "Gradient Matrix: [[ 0.01219234  0.05350728  0.05388232  0.05125088  0.05529673  0.00832347\n",
      "   0.03140348  0.05978367  0.01164812]\n",
      " [-0.01815533 -0.00506678 -0.00019458 -0.01984388 -0.00863587 -0.00576099\n",
      "  -0.00150037 -0.02490365 -0.00465679]]\n",
      "\n",
      "Model Loss: 84.31352058804059\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 12\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999989944313, 1.0055687324575987e-09]\n",
      "\n",
      "Weight Matrix: [[0.88352884 0.77347224 0.76802069 0.79502681 0.77182532 0.88785924\n",
      "  0.83824982 0.75117831 0.93620999]\n",
      " [1.06107387 1.03563423 1.0208806  1.06710255 1.03507395 1.04258164\n",
      "  1.01784674 1.07949969 0.99833876]]\n",
      "\n",
      "Gradient Norm: 0.1087809565748144\n",
      "\n",
      "Gradient Matrix: [[ 0.00383238  0.04425262  0.04322918  0.04545602  0.04550519  0.00014691\n",
      "   0.0233648   0.04914533  0.01112759]\n",
      " [-0.01218606  0.00239547  0.00627537 -0.01363997 -0.0025529   0.00168606\n",
      "   0.00414905 -0.01884901 -0.00283388]]\n",
      "\n",
      "Model Loss: 81.40136347731737\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 13\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.999999999185835, 8.141649827559354e-10]\n",
      "\n",
      "Weight Matrix: [[0.8748846  0.74887153 0.74340198 0.77108668 0.74672595 0.88055793\n",
      "  0.82220195 0.72418835 0.92770549]\n",
      " [1.0641562  1.03359572 1.01707146 1.07086952 1.03441408 1.04099672\n",
      "  1.01451963 1.08524921 0.99621575]]\n",
      "\n",
      "Gradient Norm: 0.0855565954424041\n",
      "\n",
      "Gradient Matrix: [[-0.00524712  0.03372463  0.03125385  0.03851658  0.03437662 -0.00900596\n",
      "   0.01433864  0.03724688  0.01041498]\n",
      " [-0.00541253  0.01059215  0.01334216 -0.00675708  0.00421121  0.00962585\n",
      "   0.01037976 -0.01210839 -0.00074587]]\n",
      "\n",
      "Model Loss: 79.4364187630004\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 14\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999992843251, 7.156749045022219e-10]\n",
      "\n",
      "Weight Matrix: [[0.86831974 0.72567252 0.72056475 0.74760218 0.72309388 0.87550777\n",
      "  0.80769451 0.6988036  0.91886355]\n",
      " [1.06548128 1.02905445 1.01093058 1.07288786 1.03175652 1.03696183\n",
      "  1.00914416 1.08941798 0.99334392]]\n",
      "\n",
      "Gradient Norm: 0.07172382924677045\n",
      "\n",
      "Gradient Matrix: [[-0.01444066  0.02252267  0.01875887  0.03073356  0.02280997 -0.01869891\n",
      "   0.00495508  0.02500753  0.0094632 ]\n",
      " [ 0.00174126  0.0188841   0.0205234   0.00036003  0.01122524  0.01749814\n",
      "   0.01677786 -0.0050695   0.00150442]]\n",
      "\n",
      "Model Loss: 78.23709004656759\n",
      "==============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999993061297, 6.938703111165525e-10]\n",
      "\n",
      "Weight Matrix: [[0.8642286  0.70444428 0.70011271 0.72500988 0.7014746  0.8731658\n",
      "  0.79516356 0.67558119 0.90975962]\n",
      " [1.06470455 1.02166544 1.00215741 1.07283241 1.02677844 1.03017257\n",
      "  1.00144266 1.09167247 0.98960822]]\n",
      "\n",
      "Gradient Norm: 0.07394602831727796\n",
      "\n",
      "Gradient Matrix: [[-0.02307642  0.01149921  0.00671243  0.022792    0.01184816 -0.02811156\n",
      "  -0.00399624  0.01346581  0.00832518]\n",
      " [ 0.00866452  0.02654368  0.02723065  0.00715288  0.01792566  0.02471054\n",
      "   0.02280844  0.00173804  0.00373972]]\n",
      "\n",
      "Model Loss: 77.46765920468016\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 16\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999992502184, 7.49781565214307e-10]\n",
      "\n",
      "Weight Matrix: [[0.86286306 0.68559455 0.68246046 0.70364391 0.6822237  0.87383488\n",
      "  0.78489902 0.6548846  0.90046145]\n",
      " [1.06159189 1.01122345 0.990566   1.07048643 1.01926763 1.02044962\n",
      "  0.9912397  1.09178312 0.9849265 ]]\n",
      "\n",
      "Gradient Norm: 0.08729623063727306\n",
      "\n",
      "Gradient Matrix: [[-0.03040676  0.0017542  -0.00375804  0.01555965  0.00251019 -0.03618976\n",
      "  -0.01168535  0.00361978  0.00718385]\n",
      " [ 0.01465961  0.03290018  0.03286993  0.01299804  0.02366139  0.03070308\n",
      "   0.02790806  0.0076641   0.00571437]]\n",
      "\n",
      "Model Loss: 76.7328706410387\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 17\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999990941677, 9.058323687661342e-10]\n",
      "\n",
      "Weight Matrix: [[0.86428156 0.669289   0.6677584  0.68367538 0.66545859 0.87758919\n",
      "  0.77699591 0.6368347  0.89100632]\n",
      " [1.05606314 0.99769305 0.9761169  1.06578091 1.00916147 1.00776659\n",
      "  0.97849387 1.08966862 0.97926917]]\n",
      "\n",
      "Gradient Norm: 0.10142962296831863\n",
      "\n",
      "Gradient Matrix: [[-0.03567839 -0.00559667 -0.01155281  0.00985482 -0.00437749 -0.04191154\n",
      "  -0.01736231 -0.00369764  0.00629161]\n",
      " [ 0.01908925  0.03741709  0.03692985  0.01730994  0.02784555  0.0349954\n",
      "   0.03158323  0.01207631  0.00716878]]\n",
      "\n",
      "Model Loss: 75.70559436508304\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 18\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999987825471, 1.2174528774457504e-09]\n",
      "\n",
      "Weight Matrix: [[0.86832174 0.65541175 0.65585823 0.66508362 0.65104542 0.8842389\n",
      "  0.77133257 0.62129363 0.88138606]\n",
      " [1.04821001 0.98121722 0.95892871 1.05881203 0.9965596  0.99225946\n",
      "  0.96330954 1.08541554 0.97266956]]\n",
      "\n",
      "Gradient Norm: 0.10998627294552783\n",
      "\n",
      "Gradient Matrix: [[-0.03834726 -0.00979286 -0.0159372   0.00622394 -0.00833923 -0.04459283\n",
      "  -0.02052763 -0.00797842  0.00585236]\n",
      " [ 0.02154768  0.03977624  0.03909266  0.01970096  0.03013597  0.03729026\n",
      "   0.03352853  0.01456168  0.00791981]]\n",
      "\n",
      "Model Loss: 74.22721964984198\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 19\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999982024126, 1.7975874939467647e-09]\n",
      "\n",
      "Weight Matrix: [[0.87461016 0.64358061 0.64633187 0.64766443 0.63862097 0.89334451\n",
      "  0.76758221 0.60788392 0.8715463 ]\n",
      " [1.03828448 0.96210254 0.93926645 1.04983137 0.98170917 0.97421362\n",
      "  0.94592562 1.07926787 0.96522095]]\n",
      "\n",
      "Gradient Norm: 0.11069535527814774\n",
      "\n",
      "Gradient Matrix: [[-0.03825428 -0.0106359  -0.01673724  0.00483482 -0.00929618 -0.04405898\n",
      "  -0.02103905 -0.00911118  0.0059386 ]\n",
      " [ 0.02194311  0.03992625  0.03929611  0.02007374  0.03048886  0.03754087\n",
      "   0.03368853  0.01502185  0.00791822]]\n",
      "\n",
      "Model Loss: 72.331229619378\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 20\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999971374531, 2.862546874348644e-09]\n",
      "\n",
      "Weight Matrix: [[0.88260756 0.6332104  0.63853719 0.63107017 0.62764264 0.90427402\n",
      "  0.76525508 0.59603821 0.86139852]\n",
      " [1.02666231 0.94078394 0.91750968 1.03921181 0.96496966 0.95403109\n",
      "  0.92668475 1.07159172 0.95706203]]\n",
      "\n",
      "Gradient Norm: 0.10396740482129561\n",
      "\n",
      "Gradient Matrix: [[-0.03565595 -0.00849289 -0.01434006  0.0054791  -0.00753663 -0.04064254\n",
      "  -0.01912357 -0.00737342  0.00648407]\n",
      " [ 0.020487    0.03807714  0.03772905  0.01862238  0.02912009  0.03594887\n",
      "   0.03224987  0.01365925  0.00724975]]\n",
      "\n",
      "Model Loss: 70.18784591960157\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 21\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999951902077, 4.809792361857612e-09]\n",
      "\n",
      "Weight Matrix: [[0.89167533 0.62360465 0.63171197 0.61486987 0.61745782 0.91628554\n",
      "  0.76376119 0.58507104 0.85083791]\n",
      " [1.01379122 0.91777595 0.89410786 1.02739829 0.94676629 0.93218557\n",
      "  0.90599096 1.06282483 0.94835597]]\n",
      "\n",
      "Gradient Norm: 0.09195709108561047\n",
      "\n",
      "Gradient Matrix: [[-0.03111423 -0.00414527 -0.00954785  0.00766182 -0.00364419 -0.03504762\n",
      "  -0.01530297 -0.0033652   0.00733801]\n",
      " [ 0.01761822  0.0346452   0.03477215  0.01576359  0.02642908  0.03290237\n",
      "   0.02957585  0.01089971  0.00609209]]\n",
      "\n",
      "Model Loss: 68.00889600961568\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 22\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999916653604, 8.334639668275178e-09]\n",
      "\n",
      "Weight Matrix: [[0.90114343 0.61405016 0.62507184 0.59861359 0.60738133 0.92861261\n",
      "  0.76247957 0.57425966 0.8397587 ]\n",
      " [1.00013595 0.89361975 0.86953305 1.01485506 0.92754195 0.90917567\n",
      "  0.88426647 1.05342306 0.93927032]]\n",
      "\n",
      "Gradient Norm: 0.07783501113502465\n",
      "\n",
      "Gradient Matrix: [[-0.02530605  0.0014608  -0.00334345  0.01075318  0.00161183 -0.02812753\n",
      "  -0.01026069  0.00211227  0.0083495 ]\n",
      " [ 0.01388528  0.030161    0.03089966  0.01202229  0.02289983  0.02887373\n",
      "   0.02610134  0.00727654  0.00464788]]\n",
      "\n",
      "Model Loss: 65.96349226313511\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 23\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999854245623, 1.457543770063961e-08]\n",
      "\n",
      "Weight Matrix: [[0.91036504 0.60389293 0.61789229 0.58188695 0.59676934 0.94053209\n",
      "  0.76082173 0.5629214  0.82806082]\n",
      " [0.9861306  0.86883466 0.84423875 1.00201997 0.90771574 0.88548474\n",
      "  0.86191636 1.04381407 0.92996252]]\n",
      "\n",
      "Gradient Norm: 0.06518968728598322\n",
      "\n",
      "Gradient Matrix: [[-0.01885658  0.00745219  0.00333411  0.01414206  0.00740416 -0.02066423\n",
      "  -0.00470535  0.00819669  0.00943482]\n",
      " [ 0.00982923  0.02517388  0.02658045  0.00791738  0.01900629  0.02432461\n",
      "   0.02223346  0.00331435  0.00308572]]\n",
      "\n",
      "Model Loss: 64.13506932501787\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 24\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.999999974759846, 2.524015392499903e-08]\n",
      "\n",
      "Weight Matrix: [[0.91875496 0.59258758 0.60956582 0.564349   0.58507962 0.95140756\n",
      "  0.7582815  0.5504772  0.81564888]\n",
      " [0.97214374 0.84387902 0.8186288  0.98927061 0.88765207 0.86154963\n",
      "  0.83930372 1.03436371 0.92057212]]\n",
      "\n",
      "Gradient Norm: 0.05726147459854247\n",
      "\n",
      "Gradient Matrix: [[-0.01227919  0.01315225  0.00971884  0.01733279  0.01297078 -0.01325592\n",
      "   0.00072889  0.01408754  0.01058189]\n",
      " [ 0.00590786  0.0201846   0.02222077  0.00389065  0.01515571  0.01966358\n",
      "   0.0183064  -0.00054509  0.00152095]]\n",
      "\n",
      "Model Loss: 62.52039192691681\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 25\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999573733549, 4.26266450700008e-08]\n",
      "\n",
      "Weight Matrix: [[0.92581932 0.57972463 0.59963582 0.54575368 0.57191135 0.96071554\n",
      "  0.75446845 0.53649523 0.80243082]\n",
      " [0.95845669 0.81912147 0.79303458 0.97690217 0.86763925 0.83773544\n",
      "  0.81673145 1.02535456 0.91121614]]\n",
      "\n",
      "Gradient Norm: 0.05533892477624658\n",
      "\n",
      "Gradient Matrix: [[-6.02254181e-03  1.80782174e-02  1.52433218e-02  1.99683024e-02\n",
      "   1.77128160e-02 -6.35195837e-03  5.53740516e-03  1.91392934e-02\n",
      "   1.17872412e-02]\n",
      " [ 2.46944981e-03  1.56167729e-02  1.81638156e-02  2.89911812e-04\n",
      "   1.16793926e-02  1.52599726e-02  1.46030034e-02 -3.96126883e-03\n",
      "   4.04158420e-05]]\n",
      "\n",
      "Model Loss: 61.05448042748671\n",
      "==============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 26\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999999305421323, 6.945786767322137e-08]\n",
      "\n",
      "Weight Matrix: [[0.93118451 0.56504436 0.58781321 0.52595971 0.55702255 0.96806667\n",
      "  0.74912568 0.52071252 0.78832314]\n",
      " [0.94525255 0.7948213  0.76769688 0.96511374 0.84787482 0.81431257\n",
      "  0.79442522 1.01697364 0.90198355]]\n",
      "\n",
      "Gradient Norm: 0.057590529739459204\n",
      "\n",
      "Gradient Matrix: [[-0.00053785  0.02188333  0.01951003  0.02180637  0.02124079 -0.00035246\n",
      "   0.00936126  0.02291017  0.01298461]\n",
      " [-0.00024061  0.01181407  0.01471458 -0.00261705  0.00884669  0.01146914\n",
      "   0.01139827 -0.00667986 -0.00126171]]\n",
      "\n",
      "Model Loss: 59.646350777120794\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 27\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999998914294695, 1.0857053051945414e-07]\n",
      "\n",
      "Weight Matrix: [[0.93462234 0.54844174 0.57398013 0.50493304 0.54032928 0.97322349\n",
      "  0.74213461 0.50303786 0.77326169]\n",
      " [0.93261333 0.77111802 0.74275265 0.95400171 0.82845733 0.79143868\n",
      "  0.77251879 1.00930714 0.89292913]]\n",
      "\n",
      "Gradient Norm: 0.060730973897548536\n",
      "\n",
      "Gradient Matrix: [[ 0.00375468  0.02432439  0.02226597  0.0226882   0.02336011  0.00438139\n",
      "   0.01197893  0.0251544   0.01404969]\n",
      " [-0.0020668   0.0090276   0.012129   -0.00463782  0.00686148  0.00860435\n",
      "   0.00894744 -0.00852314 -0.00228465]]\n",
      "\n",
      "Model Loss: 58.21591857088631\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 28\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999998373131384, 1.626868615765835e-07]\n",
      "\n",
      "Weight Matrix: [[0.93605963 0.52996243 0.55818242 0.48274438 0.52189322 0.97610542\n",
      "  0.73350961 0.48354234 0.75720975]\n",
      " [0.9205241  0.74803208 0.71823154 0.94356108 0.80938631 0.76915216\n",
      "  0.75104813 1.00234239 0.88407049]]\n",
      "\n",
      "Gradient Norm: 0.06224197317859825\n",
      "\n",
      "Gradient Matrix: [[ 0.00658816  0.02526966  0.0233963   0.02252012  0.02402081  0.00762305\n",
      "   0.01328837  0.02577699  0.01487581]\n",
      " [-0.00293667  0.00738737  0.01056298 -0.00566889  0.005836    0.00686247\n",
      "   0.00741695 -0.00939705 -0.00295784]]\n",
      "\n",
      "Model Loss: 56.72180639013475\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 29\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999997653757896, 2.3462421040037372e-07]\n",
      "\n",
      "Weight Matrix: [[0.93556819 0.50979001 0.54061282 0.45956273 0.50190333 0.97677707\n",
      "  0.72338563 0.46244293 0.74015901]\n",
      " [0.90888238 0.72547606 0.69406345 0.93369409 0.790571   0.74737981\n",
      "  0.72995744 0.99597632 0.87538999]]\n",
      "\n",
      "Gradient Norm: 0.060932496360586265\n",
      "\n",
      "Gradient Matrix: [[ 0.00790533  0.02470068  0.02290981  0.02126639  0.02326633  0.00933156\n",
      "   0.01328346  0.02478568  0.01542346]\n",
      " [-0.00285013  0.0069001   0.0100493  -0.00569667  0.00578143  0.00628905\n",
      "   0.00684639 -0.00928958 -0.00326294]]\n",
      "\n",
      "Model Loss: 55.171190985136114\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 30\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999996717352462, 3.2826475385667196e-07]\n",
      "\n",
      "Weight Matrix: [[0.9333421  0.48822716 0.52158848 0.43564525 0.48065491 0.97542588\n",
      "  0.71200129 0.44008225 0.72212553]\n",
      " [0.89751107 0.70327244 0.67009365 0.92422373 0.77184519 0.72595421\n",
      "  0.7091135  0.99002842 0.86684011]]\n",
      "\n",
      "Gradient Norm: 0.05669142415762998\n",
      "\n",
      "Gradient Matrix: [[ 0.00780408  0.02269024  0.02090944  0.0189466   0.02120108  0.00960296\n",
      "   0.01203177  0.0222619   0.01570611]\n",
      " [-0.00186253  0.00748161  0.01052385 -0.00477742  0.00662713  0.00680828\n",
      "   0.00717351 -0.00825324 -0.00322235]]\n",
      "\n",
      "Model Loss: 53.61111802153798\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 31\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999995494911423, 4.5050885761549544e-07]\n",
      "\n",
      "Weight Matrix: [[0.92967052 0.46567285 0.50152464 0.41132333 0.45852681 0.972336\n",
      "  0.6996782  0.41690471 0.70314453]\n",
      " [0.88617374 0.68117451 0.64610186 0.91491033 0.75298554 0.70463618\n",
      "  0.68832384 0.98425652 0.85835002]]\n",
      "\n",
      "Gradient Norm: 0.05031040815109368\n",
      "\n",
      "Gradient Matrix: [[ 6.46464889e-03  1.93815435e-02  1.75702556e-02  1.56372051e-02\n",
      "   1.79801176e-02  8.60670502e-03  9.66534520e-03  1.83558563e-02\n",
      "   1.57559471e-02]\n",
      " [-7.37790861e-05  8.98869053e-03  1.18600593e-02 -3.01983776e-03\n",
      "   8.24406228e-03  8.26738709e-03  8.27523816e-03 -6.39014278e-03\n",
      "  -2.87902562e-03]]\n",
      "\n",
      "Model Loss: 52.10720355239972\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 32\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999993854908409, 6.145091590888226e-07]\n",
      "\n",
      "Weight Matrix: [[0.92490835 0.44259546 0.48090442 0.38698386 0.43595531 0.96786011\n",
      "  0.68679591 0.39342736 0.68326587]\n",
      " [0.87459271 0.65888963 0.62182364 0.90547134 0.73373247 0.68313982\n",
      "  0.66735654 0.97837547 0.84983241]]\n",
      "\n",
      "Gradient Norm: 0.04364477986408448\n",
      "\n",
      "Gradient Matrix: [[ 0.00412234  0.01498947  0.01314051  0.01148251  0.01381904  0.00656694\n",
      "   0.00638748  0.01330271  0.0156047 ]\n",
      " [ 0.00236902  0.01122821  0.01388209 -0.00058508  0.01045612  0.01045889\n",
      "   0.00998903 -0.00385208 -0.00228718]]\n",
      "\n",
      "Model Loss: 50.71698758347971\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 33\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999991550210938, 8.44978906083711e-07]\n",
      "\n",
      "Weight Matrix: [[0.91944315 0.41949903 0.46024223 0.36304349 0.41340236 0.96238666\n",
      "  0.67376074 0.37020216 0.66255031]\n",
      " [0.86247133 0.63610611 0.59697529 0.89560546 0.71381355 0.66116052\n",
      "  0.64596202 0.97208019 0.84119097]]\n",
      "\n",
      "Gradient Norm: 0.039801140083011596\n",
      "\n",
      "Gradient Matrix: [[ 0.00108217  0.00982533  0.00796409  0.00671783  0.00901912  0.00378386\n",
      "   0.00248955  0.00745374  0.01528254]\n",
      " [ 0.00525697  0.01394702  0.01635799  0.00229978  0.01303964  0.01311914\n",
      "   0.01211189 -0.0008539  -0.00151461]]\n",
      "\n",
      "Model Loss: 49.46542863988122\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 34\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999988124858108, 1.1875141892043568e-06]\n",
      "\n",
      "Weight Matrix: [[0.91365575 0.39688011 0.44003833 0.33991389 0.39131553 0.95629973\n",
      "  0.66096716 0.34776746 0.64106531]\n",
      " [0.84952195 0.61252488 0.57128305 0.88502228 0.69297001 0.63840699\n",
      "  0.6238979  0.9650742  0.83232918]]\n",
      "\n",
      "Gradient Norm: 0.041567955232101765\n",
      "\n",
      "Gradient Matrix: [[-0.00225812  0.00432665  0.00250571  0.00169205  0.00399113  0.00066165\n",
      "  -0.00163531  0.00130325  0.01482702]\n",
      " [ 0.00830495  0.01682016  0.01898957  0.00533258  0.01572004  0.01592023\n",
      "   0.01439016  0.00231355 -0.00064964]]\n",
      "\n",
      "Model Loss: 48.33133710322902\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 35\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999982739676496, 1.7260323504889965e-06]\n",
      "\n",
      "Weight Matrix: [[0.9078754  0.37517545 0.42072548 0.31795923 0.37008097 0.94993198\n",
      "  0.64875307 0.32659031 0.61887962]\n",
      " [0.83549862 0.58789486 0.5445158  0.87347544 0.67098541 0.61463612\n",
      "  0.60095696 0.95710271 0.82316071]]\n",
      "\n",
      "Gradient Norm: 0.04805695515142923\n",
      "\n",
      "Gradient Matrix: [[-0.00541415 -0.00094437 -0.00265545 -0.00314034 -0.00075267 -0.00229454\n",
      "  -0.00550163 -0.00452544  0.01429275]\n",
      " [ 0.01115799  0.01946037  0.02142094  0.00815137  0.01818044  0.01847979\n",
      "   0.01652003  0.00529169  0.00019662]]\n",
      "\n",
      "Model Loss: 47.25299862446456\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 36\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999973836570397, 2.616342960274917e-06]\n",
      "\n",
      "Weight Matrix: [[0.90233492 0.35470712 0.40261435 0.29745189 0.34997555 0.94351663\n",
      "  0.63735364 0.30700789 0.59605634]\n",
      " [0.82023042 0.56204773 0.51651733 0.86079494 0.64771334 0.58968673\n",
      "  0.57699534 0.94798587 0.81362038]]\n",
      "\n",
      "Gradient Norm: 0.05554338278699931\n",
      "\n",
      "Gradient Matrix: [[-0.00787112 -0.00536276 -0.00688994 -0.00727679 -0.00465894 -0.00453637\n",
      "  -0.00857977 -0.00935997  0.01375329]\n",
      " [ 0.01343272  0.0214629   0.02327825  0.01038097  0.02009444  0.02040427\n",
      "   0.01817573  0.00769732  0.0009    ]]\n",
      "\n",
      "Model Loss: 46.154348476663195\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 37\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999958493066401, 4.150693359929864e-06]\n",
      "\n",
      "Weight Matrix: [[0.89713541 0.33563653 0.38584873 0.27853568 0.33112813 0.9371486\n",
      "  0.62686253 0.28918071 0.57264571]\n",
      " [0.8036485  0.53492507 0.4872319  0.84691211 0.62309905 0.56350533\n",
      "  0.55195562 0.9376454  0.80367348]]\n",
      "\n",
      "Gradient Norm: 0.06068029538354947\n",
      "\n",
      "Gradient Matrix: [[-0.00918186 -0.00835831 -0.00963479 -0.01026251 -0.00723799 -0.00557782\n",
      "  -0.0103845  -0.01260935  0.01328962]\n",
      " [ 0.01478821  0.0224789   0.02423472  0.0116995   0.02118079  0.02135855\n",
      "   0.0190657   0.00919328  0.00134568]]\n",
      "\n",
      "Model Loss: 44.98107740033384\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 38\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999931210568569, 6.878943143112034e-06]\n",
      "\n",
      "Weight Matrix: [[0.89222999 0.31793976 0.3703831  0.26120592 0.31350101 0.93076543\n",
      "  0.61721062 0.27306967 0.54867985]\n",
      " [0.78579974 0.50659074 0.45671704 0.83187136 0.59718954 0.53615795\n",
      "  0.5258788  0.92611781 0.79332095]]\n",
      "\n",
      "Gradient Norm: 0.06153972477083634\n",
      "\n",
      "Gradient Matrix: [[-0.00907291 -0.00955121 -0.0105277  -0.01179232 -0.00818194 -0.00511123\n",
      "  -0.01058741 -0.01389948  0.01296786]\n",
      " [ 0.01500397  0.02229383  0.02408026  0.01190686  0.02126328  0.02113666\n",
      "   0.01899855  0.00956363  0.00145605]]\n",
      "\n",
      "Model Loss: 43.72748464562787\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 39\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.999988174122665, 1.1825877335038204e-05]\n",
      "\n",
      "Weight Matrix: [[0.88743212 0.30141266 0.35599057 0.2453122  0.29689836 0.92415433\n",
      "  0.60817059 0.25844463 0.52417151]\n",
      " [0.76684253 0.47722449 0.42513956 0.81582478 0.57012889 0.50782443\n",
      "  0.49890122 0.91355013 0.78259846]]\n",
      "\n",
      "Gradient Norm: 0.05764446796659031\n",
      "\n",
      "Gradient Matrix: [[-0.00751567 -0.00885413 -0.00950754 -0.0117842  -0.00745274 -0.00308835\n",
      "  -0.00911444 -0.01316808  0.01281693]\n",
      " [ 0.01403732  0.0208814   0.02277096  0.01097352  0.02031393  0.01970736\n",
      "   0.01793169  0.0087665   0.0012125 ]]\n",
      "\n",
      "Model Loss: 42.438255106123236\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 40\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999791460960143, 2.0853903985668763e-05]\n",
      "\n",
      "Weight Matrix: [[0.88244738 0.28570624 0.34230129 0.2305843  0.28100189 0.91698483\n",
      "  0.5993892  0.24492425 0.49911735]\n",
      " [0.74702443 0.44709736 0.3927549  0.79900982 0.54213891 0.47877594\n",
      "  0.47123636 0.90017815 0.7715694 ]]\n",
      "\n",
      "Gradient Norm: 0.049895096931977766\n",
      "\n",
      "Gradient Matrix: [[-0.00473266 -0.00649963 -0.00683741 -0.01039967 -0.00530115  0.00026689\n",
      "  -0.00618277 -0.01068692  0.01281877]\n",
      " [ 0.01203744  0.01841063  0.02043991  0.00905039  0.01846202  0.01722006\n",
      "   0.01598248  0.00694544  0.00066093]]\n",
      "\n",
      "Model Loss: 41.18433744708137\n",
      "==============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 41\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999627921602859, 3.72078397140117e-05]\n",
      "\n",
      "Weight Matrix: [[0.87692121 0.27038479 0.32886299 0.21667586 0.26542568 0.90885949\n",
      "  0.59044088 0.23203937 0.47350497]\n",
      " [0.72664646 0.41653435 0.35987423 0.78171484 0.51348886 0.44934003\n",
      "  0.44314566 0.88629177 0.76031347]]\n",
      "\n",
      "Gradient Norm: 0.04048803504929215\n",
      "\n",
      "Gradient Matrix: [[-0.00113701 -0.00298362 -0.00303916 -0.00800549 -0.00220497  0.00451854\n",
      "  -0.0022555  -0.00700116  0.01291546]\n",
      " [ 0.00930944  0.01520167  0.01736483  0.0064334   0.0159649   0.01397081\n",
      "   0.01339773  0.00439508 -0.00010093]]\n",
      "\n",
      "Model Loss: 40.02816068712838\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 42\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9999337821107734, 6.621788922657063e-05]\n",
      "\n",
      "Weight Matrix: [[0.87049175 0.25499427 0.3152101  0.20321699 0.24977786 0.89937091\n",
      "  0.58089069 0.21930631 0.44732142]\n",
      " [0.70602197 0.38587288 0.32682612 0.7642395  0.48446061 0.41986021\n",
      "  0.41490468 0.87219474 0.74891333]]\n",
      "\n",
      "Gradient Norm: 0.03280501250542279\n",
      "\n",
      "Gradient Matrix: [[ 0.00276879  0.00104893  0.00123102 -0.00509274  0.00124659  0.00912561\n",
      "   0.00206834 -0.00280729  0.01302717]\n",
      " [ 0.00624188  0.01164694  0.0139036   0.0034959   0.01315114  0.01033945\n",
      "   0.01049386  0.00149451 -0.00094834]]\n",
      "\n",
      "Model Loss: 38.99858208519671\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 43\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9998839784722141, 0.00011602152778588937]\n",
      "\n",
      "Weight Matrix: [[0.86283763 0.23912801 0.30092829 0.18986615 0.23371716 0.88815406\n",
      "  0.57035336 0.20629677 0.42056169]\n",
      " [0.68543827 0.35542536 0.29392063 0.74685788 0.45531556 0.39065746\n",
      "  0.38677147 0.85816625 0.73744225]]\n",
      "\n",
      "Gradient Norm: 0.03023134276694173\n",
      "\n",
      "Gradient Matrix: [[ 0.00649648  0.00493039  0.00531364 -0.00218411  0.00447186  0.01355457\n",
      "   0.00618397  0.00118126  0.01306901]\n",
      " [ 0.00322487  0.00812751  0.01041846  0.00061398  0.01035549  0.00671531\n",
      "   0.00758931 -0.00136729 -0.00175514]]\n",
      "\n",
      "Model Loss: 38.087653961618734\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 44\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9998019413672354, 0.00019805863276452327]\n",
      "\n",
      "Weight Matrix: [[0.85371398 0.22248104 0.28570618 0.17635457 0.21699739 0.87492649\n",
      "  0.55853905 0.19269513 0.39323644]\n",
      " [0.66512681 0.32545136 0.26142151 0.72978923 0.42626837 0.36199962\n",
      "  0.35896215 0.84442981 0.72595397]]\n",
      "\n",
      "Gradient Norm: 0.032566320033683115\n",
      "\n",
      "Gradient Matrix: [[ 0.00964444  0.00806611  0.00863752  0.00023998  0.00697539  0.01735992\n",
      "   0.00958317  0.00433296  0.01295779]\n",
      " [ 0.00058676  0.00495195  0.00721268 -0.0018909   0.00786634  0.00343311\n",
      "   0.00495184 -0.0038499  -0.00241084]]\n",
      "\n",
      "Model Loss: 37.26754705749449\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 45\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9996728371308384, 0.00032716286916151255]\n",
      "\n",
      "Weight Matrix: [[0.84297535 0.20488999 0.26937207 0.16252017 0.19949851 0.85951475\n",
      "  0.54528262 0.1783402  0.36537966]\n",
      " [0.64524405 0.29614098 0.22952915 0.71317852 0.39746941 0.33408155\n",
      "  0.33163511 0.83113158 0.71447516]]\n",
      "\n",
      "Gradient Norm: 0.03609195266205118\n",
      "\n",
      "Gradient Matrix: [[ 0.01192326  0.00997513  0.01075259  0.00177839  0.00837147  0.02021221\n",
      "   0.01189725  0.00613991  0.01260679]\n",
      " [-0.00143382  0.0023315   0.00449794 -0.00377832  0.00589889  0.00073709\n",
      "   0.00277513 -0.00568956 -0.00282493]]\n",
      "\n",
      "Model Loss: 36.51689027337499\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 46\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9994784879734989, 0.0005215120265010141]\n",
      "\n",
      "Weight Matrix: [[0.83058773 0.18636081 0.25191848 0.14833169 0.18124715 0.84187006\n",
      "  0.53055936 0.16325354 0.33705764]\n",
      " [0.62586162 0.2676082  0.19837356 0.69708576 0.36899552 0.30701575\n",
      "  0.3048831  0.81832732 0.70299968]]\n",
      "\n",
      "Gradient Norm: 0.03768871825486214\n",
      "\n",
      "Gradient Matrix: [[ 0.01314349  0.01028061  0.01131531  0.00211248  0.00836712  0.0218785\n",
      "   0.01288209  0.00621165  0.01191243]\n",
      " [-0.00268408  0.00038461  0.00239275 -0.00488752  0.00459303 -0.00122471\n",
      "   0.00118141 -0.00670017 -0.00292111]]\n",
      "\n",
      "Model Loss: 35.84496767729646\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 47\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9991964580045264, 0.000803541995473562]\n",
      "\n",
      "Weight Matrix: [[0.81663257 0.16708836 0.23351838 0.1339048  0.16243002 0.82207771\n",
      "  0.51449193 0.14765758 0.30838067]\n",
      " [0.60696389 0.23989239 0.16801579 0.68148237 0.34084778 0.28083212\n",
      "  0.27873174 0.80597677 0.69148356]]\n",
      "\n",
      "Gradient Norm: 0.03588500227248282\n",
      "\n",
      "Gradient Matrix: [[ 0.01319387  0.00867869  0.01005833  0.00099558  0.00673496  0.02218579\n",
      "   0.01237762  0.00424963  0.01073906]\n",
      " [-0.00308303 -0.00085226  0.00093114 -0.00512645  0.00402015 -0.0023946\n",
      "   0.00023005 -0.00676576 -0.00262867]]\n",
      "\n",
      "Model Loss: 35.30577892656913\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 48\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9987961071183282, 0.0012038928816718365]\n",
      "\n",
      "Weight Matrix: [[0.80130323 0.14746986 0.2145346  0.11951052 0.1434015  0.80036189\n",
      "  0.49735165 0.13198547 0.27951828]\n",
      " [0.58845262 0.21296865 0.13845843 0.66625453 0.31295651 0.25548724\n",
      "  0.25314512 0.79394559 0.67984043]]\n",
      "\n",
      "Gradient Norm: 0.030785552045688228\n",
      "\n",
      "Gradient Matrix: [[ 1.20419360e-02  4.92323346e-03  6.78074376e-03 -1.74531770e-03\n",
      "   3.30588449e-03  2.10066760e-02  1.02850727e-02  3.75586503e-05\n",
      "   8.91054592e-03]\n",
      " [-2.62476037e-03 -1.43599324e-03  5.19559154e-05 -4.47500645e-03\n",
      "   4.17704420e-03 -2.81403354e-03 -9.30987502e-05 -5.84782410e-03\n",
      "  -1.88038597e-03]]\n",
      "\n",
      "Model Loss: 34.99678045386193\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 49\n",
      "Learning Rate: 5.960464477539063e-09\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9982386304453473, 0.0017613695546527459]\n",
      "\n",
      "Weight Matrix: [[0.78686775 0.12899532 0.19665777 0.10595558 0.12548254 0.77991232\n",
      "  0.48121082 0.11722721 0.25233886]\n",
      " [0.57102075 0.18761484 0.11062457 0.65191462 0.28669158 0.23162022\n",
      "  0.22905046 0.78261594 0.66887621]]\n",
      "\n",
      "Gradient Norm: 0.028890611554156783\n",
      "\n",
      "Gradient Matrix: [[ 7.49950621e-03 -8.18530326e-03 -4.78324709e-03 -1.11853156e-02\n",
      "  -7.99458782e-03  1.52452011e-02  2.50499128e-03 -1.40574897e-02\n",
      "   2.96269482e-03]\n",
      " [-3.62615398e-04 -2.21760791e-03 -1.53785704e-03 -1.59562544e-03\n",
      "   5.58114973e-03 -2.80751540e-03 -6.26746968e-05 -2.17032791e-03\n",
      "   8.56644689e-04]]\n",
      "\n",
      "Model Loss: 35.0487613232124\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 50\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9982151587665996, 0.0017848412334002845]\n",
      "\n",
      "Weight Matrix: [[0.7851178  0.12881385 0.19613609 0.10607411 0.125282   0.7773878\n",
      "  0.47996032 0.11763295 0.25104259]\n",
      " [0.57005701 0.1868366  0.10977835 0.65107419 0.28513346 0.23090097\n",
      "  0.22805673 0.78183297 0.66779054]]\n",
      "\n",
      "Gradient Norm: 0.02889061154834072\n",
      "\n",
      "Gradient Matrix: [[ 7.49950621e-03 -8.18530324e-03 -4.78324707e-03 -1.11853156e-02\n",
      "  -7.99458780e-03  1.52452011e-02  2.50499130e-03 -1.40574897e-02\n",
      "   2.96269483e-03]\n",
      " [-3.62615399e-04 -2.21760790e-03 -1.53785704e-03 -1.59562544e-03\n",
      "   5.58114973e-03 -2.80751539e-03 -6.26746930e-05 -2.17032791e-03\n",
      "   8.56644684e-04]]\n",
      "\n",
      "Model Loss: 35.02505010174188\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 51\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9981684300257061, 0.0018315699742939109]\n",
      "\n",
      "Weight Matrix: [[0.78172472 0.12847509 0.1951355  0.10631057 0.1249042  0.77250042\n",
      "  0.47754203 0.11843099 0.24853566]\n",
      " [0.56818453 0.18532918 0.10814036 0.64943995 0.28210834 0.22950861\n",
      "  0.22612974 0.78030966 0.66567717]]\n",
      "\n",
      "Gradient Norm: 0.028933828308410233\n",
      "\n",
      "Gradient Matrix: [[ 7.43206082e-03 -8.32323039e-03 -4.91250782e-03 -1.12470819e-02\n",
      "  -8.11273555e-03  1.50724099e-02  2.39307129e-03 -1.41548913e-02\n",
      "   2.84792232e-03]\n",
      " [-3.61486739e-04 -2.26312895e-03 -1.59832196e-03 -1.58133030e-03\n",
      "   5.56110647e-03 -2.85756716e-03 -9.91007007e-05 -2.14881233e-03\n",
      "   8.97915989e-04]]\n",
      "\n",
      "Model Loss: 34.98029227498528\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 52\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.998097580279159, 0.0019024197208410516]\n",
      "\n",
      "Weight Matrix: [[0.77679053 0.12801291 0.19370585 0.10666919 0.1243805  0.76541203\n",
      "  0.47404037 0.11961716 0.24490636]\n",
      " [0.56545397 0.18314258 0.10576698 0.6470536  0.27770144 0.22749082\n",
      "  0.22332873 0.77808339 0.66258472]]\n",
      "\n",
      "Gradient Norm: 0.02902276835843149\n",
      "\n",
      "Gradient Matrix: [[ 0.00731493 -0.00857588 -0.00514803 -0.01135424 -0.00832905  0.01475223\n",
      "   0.00219047 -0.0143291   0.00263024]\n",
      " [-0.00036856 -0.00236245 -0.00172697 -0.00156197  0.00551512 -0.00296445\n",
      "  -0.00017871 -0.00211569  0.00097665]]\n",
      "\n",
      "Model Loss: 34.91809294022993\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 53\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9980008525619072, 0.001999147438092829]\n",
      "\n",
      "Weight Matrix: [[0.77041109 0.12746722 0.19190074 0.10715616 0.12374716 0.75628281\n",
      "  0.46953912 0.12119279 0.24024488]\n",
      " [0.56191411 0.18032989 0.1027186  0.64395423 0.27199456 0.22489861\n",
      "  0.21971382 0.77518869 0.6585541 ]]\n",
      "\n",
      "Gradient Norm: 0.029153750588412818\n",
      "\n",
      "Gradient Matrix: [[ 0.00716962 -0.00891032 -0.005458   -0.01148103 -0.00861518  0.01431169\n",
      "   0.00192432 -0.01454787  0.00232042]\n",
      " [-0.00040331 -0.00253486 -0.00194312 -0.00155572  0.00542665 -0.00314469\n",
      "  -0.00031842 -0.00208975  0.00108452]]\n",
      "\n",
      "Model Loss: 34.84282332156111\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 54\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9978757886272129, 0.00212421137278701]\n",
      "\n",
      "Weight Matrix: [[0.7626745  0.12687998 0.18977386 0.10777657 0.12304196 0.7452692\n",
      "  0.46411871 0.12316066 0.23464248]\n",
      " [0.5576146  0.17694975 0.09906221 0.64018088 0.26506871 0.22178847\n",
      "  0.21534832 0.77165983 0.6536202 ]]\n",
      "\n",
      "Gradient Norm: 0.029320245221918777\n",
      "\n",
      "Gradient Matrix: [[ 0.00702067 -0.00928948 -0.00580644 -0.01159765 -0.00893889  0.01377993\n",
      "   0.00162524 -0.01477427  0.0019296 ]\n",
      " [-0.00048954 -0.00280485 -0.00227165 -0.00158442  0.00527518 -0.00341914\n",
      "  -0.00053967 -0.00209331  0.00121219]]\n",
      "\n",
      "Model Loss: 34.75951180029221\n",
      "==============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 55\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9977194501436579, 0.0022805498563419923]\n",
      "\n",
      "Weight Matrix: [[0.75365968 0.12629184 0.18737593 0.10853165 0.12230118 0.73252216\n",
      "  0.45785398 0.12552144 0.22819078]\n",
      " [0.55260847 0.17306881 0.09487377 0.63577482 0.25700661 0.21822431\n",
      "  0.21030105 0.76753314 0.64781319]]\n",
      "\n",
      "Gradient Norm: 0.029517758061989988\n",
      "\n",
      "Gradient Matrix: [[ 0.00689054 -0.00967913 -0.00616012 -0.01167623 -0.00926983  0.01318252\n",
      "   0.00132145 -0.01497401  0.00146785]\n",
      " [-0.00065081 -0.00319717 -0.00273803 -0.00166926  0.00504026 -0.00380833\n",
      "  -0.00086412 -0.00214783  0.00135092]]\n",
      "\n",
      "Model Loss: 34.67377825121244\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 56\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9975286859285594, 0.0024713140714406104]\n",
      "\n",
      "Weight Matrix: [[0.7434357  0.12573989 0.18475265 0.10941704 0.12155759 0.71818657\n",
      "  0.45081279 0.1282713  0.22098142]\n",
      " [0.5469541  0.16876353 0.09024017 0.63078128 0.24789455 0.21427889\n",
      "  0.20464803 0.76284869 0.64115972]]\n",
      "\n",
      "Gradient Norm: 0.029754184679533724\n",
      "\n",
      "Gradient Matrix: [[ 0.00679456 -0.01005508 -0.0064954  -0.01169691 -0.0095854   0.0125357\n",
      "   0.00103295 -0.01512245  0.00094247]\n",
      " [-0.00090584 -0.00373187 -0.00336321 -0.00182655  0.00470556 -0.00432787\n",
      "  -0.00130935 -0.00226953  0.00149419]]\n",
      "\n",
      "Model Loss: 34.59176066380639\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 57\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9973004486563112, 0.0026995513436888267]\n",
      "\n",
      "Weight Matrix: [[0.73206224 0.12525713 0.18194424 0.1104223  0.12083968 0.70240181\n",
      "  0.44305593 0.1314012  0.21310601]\n",
      " [0.54071609 0.16412098 0.08526005 0.62525017 0.23782343 0.21003421\n",
      "  0.19847334 0.75765098 0.63368345]]\n",
      "\n",
      "Gradient Norm: 0.030060731390966274\n",
      "\n",
      "Gradient Matrix: [[ 0.00673668 -0.01040887 -0.00680379 -0.01165273 -0.00987557  0.0118415\n",
      "   0.00076668 -0.01521019  0.00035671]\n",
      " [-0.00126464 -0.00441992 -0.00415922 -0.00206406  0.00426238 -0.00498468\n",
      "  -0.00188512 -0.0024657   0.00163919]]\n",
      "\n",
      "Model Loss: 34.51997506756566\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 58\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9970321426621801, 0.002967857337819847]\n",
      "\n",
      "Weight Matrix: [[0.71959133 0.12487377 0.17898687 0.11153212 0.12017249 0.68530412\n",
      "  0.43463863 0.1348979  0.20465665]\n",
      " [0.53396508 0.15923845 0.08004355 0.61923572 0.22688873 0.20558092\n",
      "  0.19186897 0.75198851 0.62540524]]\n",
      "\n",
      "Gradient Norm: 0.030496283038213688\n",
      "\n",
      "Gradient Matrix: [[ 0.00670692 -0.01075078 -0.00709495 -0.01155224 -0.01014546  0.01108506\n",
      "   0.00051407 -0.01524557 -0.00029112]\n",
      " [-0.00172599 -0.00526033 -0.00512606 -0.00237888  0.00371176 -0.00577452\n",
      "  -0.00259092 -0.00273266  0.00178758]]\n",
      "\n",
      "Model Loss: 34.46507363753469\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 59\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9967219567022767, 0.003278043297723235]\n",
      "\n",
      "Weight Matrix: [[0.70607035 0.1246203  0.17591565 0.11272883 0.11957985 0.66703032\n",
      "  0.42561334 0.13874661 0.19572679]\n",
      " [0.52677639 0.15422184 0.07471067 0.61279509 0.21518949 0.20101652\n",
      "  0.18493345 0.74591227 0.61634277]]\n",
      "\n",
      "Gradient Norm: 0.031140246399295277\n",
      "\n",
      "Gradient Matrix: [[ 0.00668144 -0.01110887 -0.00739577 -0.0114189  -0.01041467  0.01023511\n",
      "   0.00025156 -0.01525322 -0.00100736]\n",
      " [-0.00227721 -0.00623933 -0.00625079 -0.00275724  0.00306484 -0.00668172\n",
      "  -0.00341534 -0.00305582  0.0019455 ]]\n",
      "\n",
      "Model Loss: 34.433508690294396\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 60\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.996369112553031, 0.003630887446969014]\n",
      "\n",
      "Weight Matrix: [[0.69154599 0.12453155 0.1727687  0.11399587 0.1190874  0.64772254\n",
      "  0.41603357 0.14293454 0.18641241]\n",
      " [0.51922777 0.14918299 0.06938865 0.6059861  0.20282649 0.19644274\n",
      "  0.1777698  0.73947346 0.60650984]]\n",
      "\n",
      "Gradient Norm: 0.03207502176029916\n",
      "\n",
      "Gradient Matrix: [[ 6.62536872e-03 -1.15236235e-02 -7.74543543e-03 -1.12868046e-02\n",
      "  -1.07130896e-02  9.24818833e-03 -5.52730015e-05 -1.52683338e-02\n",
      "  -1.80156225e-03]\n",
      " [-2.89625874e-03 -7.33200649e-03 -7.50888705e-03 -3.17674000e-03\n",
      "   2.34102684e-03 -7.68110945e-03 -4.33759242e-03 -3.41215227e-03\n",
      "   2.12246871e-03]]\n",
      "\n",
      "Model Loss: 34.43114277596111\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 61\n",
      "Learning Rate: 5.960464477539063e-09\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9959981019153772, 0.0040018980846229105]\n",
      "\n",
      "Weight Matrix: [[0.67771827 0.12444706 0.16977269 0.11520215 0.11861857 0.62934084\n",
      "  0.40691328 0.1469216  0.17754479]\n",
      " [0.51204121 0.14438582 0.06432189 0.59950371 0.19105646 0.19208834\n",
      "  0.17094975 0.73334347 0.59714853]]\n",
      "\n",
      "Gradient Norm: 0.034979748935329846\n",
      "\n",
      "Gradient Matrix: [[ 0.00640301 -0.01257963 -0.00863658 -0.01111715 -0.01143594  0.00692634\n",
      "  -0.0008099  -0.01541838 -0.00355858]\n",
      " [-0.00424323 -0.00973309 -0.01028781 -0.00405709  0.00077551 -0.00982638\n",
      "  -0.00636033 -0.0041444   0.00255513]]\n",
      "\n",
      "Model Loss: 34.468527775448884\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 62\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9959811479521861, 0.004018852047813903]\n",
      "\n",
      "Weight Matrix: [[0.67607797 0.12470502 0.16963634 0.11531386 0.11876217 0.6276482\n",
      "  0.40599427 0.14746344 0.17690065]\n",
      " [0.51146554 0.14435913 0.06435067 0.59890941 0.18997891 0.19207098\n",
      "  0.17058578 0.73275791 0.59589302]]\n",
      "\n",
      "Gradient Norm: 0.03497974893166868\n",
      "\n",
      "Gradient Matrix: [[ 0.00640301 -0.01257963 -0.00863658 -0.01111715 -0.01143594  0.00692634\n",
      "  -0.0008099  -0.01541838 -0.00355858]\n",
      " [-0.00424323 -0.00973309 -0.01028781 -0.00405709  0.00077551 -0.00982638\n",
      "  -0.00636033 -0.0041444   0.00255513]]\n",
      "\n",
      "Model Loss: 34.45938739625466\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 63\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9959461540785552, 0.004053845921444672]\n",
      "\n",
      "Weight Matrix: [[0.67288993 0.1252221  0.16938402 0.11554018 0.11905323 0.62436711\n",
      "  0.40421488 0.14852834 0.17565103]\n",
      " [0.51033465 0.14429995 0.06440046 0.59774191 0.18787038 0.19203231\n",
      "  0.16986986 0.73160763 0.59343669]]\n",
      "\n",
      "Gradient Norm: 0.03501059023090741\n",
      "\n",
      "Gradient Matrix: [[ 0.00625165 -0.01271288 -0.00877584 -0.0111988  -0.01154246  0.0066836\n",
      "  -0.00096248 -0.01548645 -0.0036412 ]\n",
      " [-0.00417616 -0.00966252 -0.01022362 -0.00398737  0.00081838 -0.00977869\n",
      "  -0.00630866 -0.00407634  0.00260084]]\n",
      "\n",
      "Model Loss: 34.44217799510461\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 64\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9958906186203104, 0.0041093813796896535]\n",
      "\n",
      "Weight Matrix: [[0.66825164 0.12600887 0.16904468 0.11588881 0.11950281 0.61961418\n",
      "  0.40164112 0.15010237 0.1738386 ]\n",
      " [0.50866306 0.14419848 0.06446032 0.59601583 0.18477148 0.19196614\n",
      "  0.16881008 0.72990722 0.58982616]]\n",
      "\n",
      "Gradient Norm: 0.03506893714624131\n",
      "\n",
      "Gradient Matrix: [[ 0.00598394 -0.01293727 -0.00901259 -0.01132819 -0.01172038  0.00624289\n",
      "  -0.00122937 -0.01558603 -0.00379118]\n",
      " [-0.00406753 -0.00954963 -0.0101239  -0.00387174  0.00088355 -0.00970711\n",
      "  -0.00622875 -0.00396427  0.00268328]]\n",
      "\n",
      "Model Loss: 34.418411730925285\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 65\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9958113684851265, 0.004188631514873439]\n",
      "\n",
      "Weight Matrix: [[0.66226083 0.12707834 0.16864917 0.11636666 0.12012328 0.61351227\n",
      "  0.39834067 0.15217013 0.17150791]\n",
      " [0.50646387 0.14404554 0.06452082 0.59374364 0.18072087 0.19186793\n",
      "  0.16741467 0.72766936 0.58510232]]\n",
      "\n",
      "Gradient Norm: 0.03513692164920209\n",
      "\n",
      "Gradient Matrix: [[ 0.00564721 -0.01318688 -0.00928299 -0.0114518  -0.0119147   0.00566444\n",
      "  -0.00155553 -0.01565748 -0.00398821]\n",
      " [-0.00395914 -0.00943877 -0.01003379 -0.00374911  0.0009349  -0.00964934\n",
      "  -0.00615878 -0.00384756  0.00278512]]\n",
      "\n",
      "Model Loss: 34.38992680024981\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 66\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9957053448267572, 0.004294655173242767]\n",
      "\n",
      "Weight Matrix: [[0.65501079 0.12843869 0.1682233  0.11697417 0.12092239 0.60618408\n",
      "  0.39437712 0.15470837 0.1687033 ]\n",
      " [0.50375341 0.14383729 0.06457883 0.59093999 0.17575946 0.19173877\n",
      "  0.16569616 0.72490923 0.57930256]]\n",
      "\n",
      "Gradient Norm: 0.035180505211159785\n",
      "\n",
      "Gradient Matrix: [[ 0.0052919  -0.01339078 -0.00951828 -0.01151186 -0.01206591  0.00501234\n",
      "  -0.00188193 -0.01563655 -0.00421056]\n",
      " [-0.00389639 -0.00937811 -0.01000233 -0.00366162  0.00093315 -0.00964612\n",
      "  -0.00614024 -0.0037688   0.00288765]]\n",
      "\n",
      "Model Loss: 34.358889419334886\n",
      "==============================================================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 67\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9955702727312363, 0.004429727268763665]\n",
      "\n",
      "Weight Matrix: [[0.64658674 0.13008792 0.1677827  0.11770098 0.12189865 0.59774733\n",
      "  0.38980564 0.15768125 0.16546724]\n",
      " [0.50055487 0.14357894 0.06464117 0.58762511 0.16993362 0.19158831\n",
      "  0.16367458 0.72164783 0.57246267]]\n",
      "\n",
      "Gradient Norm: 0.03516352191182359\n",
      "\n",
      "Gradient Matrix: [[ 0.00495815 -0.01349259 -0.00966358 -0.01146264 -0.01212619  0.00433841\n",
      "  -0.00216127 -0.01547303 -0.00444064]\n",
      " [-0.00391598 -0.00940648 -0.0100691  -0.0036432   0.00084661 -0.00972977\n",
      "  -0.00620652 -0.0037622   0.00297577]]\n",
      "\n",
      "Model Loss: 34.32786099323668\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 68\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9954050824977806, 0.0045949175022193655]\n",
      "\n",
      "Weight Matrix: [[0.63706465 0.13201165 0.16733067 0.11852434 0.12303947 0.58831266\n",
      "  0.38467116 0.16103865 0.16183965]\n",
      " [0.4968998  0.14328617 0.06472613 0.58382624 0.16329658 0.19143593\n",
      "  0.16137879 0.71791349 0.56461774]]\n",
      "\n",
      "Gradient Norm: 0.035071941373840856\n",
      "\n",
      "Gradient Matrix: [[ 0.00466477 -0.01346629 -0.009693   -0.01128344 -0.01207255  0.00366917\n",
      "  -0.00237061 -0.01514547 -0.00466938]\n",
      " [-0.00403595 -0.00954281 -0.01025344 -0.00371032  0.00065994 -0.00991502\n",
      "  -0.00637373 -0.00384422  0.00304189]]\n",
      "\n",
      "Model Loss: 34.299802687762764\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 69\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9952099841467517, 0.004790015853248377]\n",
      "\n",
      "Weight Matrix: [[0.62651259 0.13418481 0.1668598  0.11941067 0.12432242 0.57798468\n",
      "  0.37900972 0.16471813 0.15785827]\n",
      " [0.49282738 0.14298412 0.06486235 0.57957687 0.15590779 0.19130959\n",
      "  0.15884558 0.71374103 0.55580216]]\n",
      "\n",
      "Gradient Norm: 0.0349296483300432\n",
      "\n",
      "Gradient Matrix: [[ 0.00440399 -0.01332352 -0.00961678 -0.01098462 -0.01191311  0.00299965\n",
      "  -0.00251733 -0.01466785 -0.00489838]\n",
      " [-0.00425091 -0.00978104 -0.01054921 -0.00385754  0.00037836 -0.01019466\n",
      "  -0.00663626 -0.00400913  0.00308786]]\n",
      "\n",
      "Model Loss: 34.27793391273738\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 70\n",
      "Learning Rate: 0.1\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9949861431782351, 0.005013856821764915]\n",
      "\n",
      "Weight Matrix: [[0.61499455 0.13657667 0.16635675 0.12031983 0.12571931 0.5668659\n",
      "  0.37285247 0.16864986 0.15355994]\n",
      " [0.48838137 0.14270409 0.06508544 0.57491397 0.14783032 0.19124274\n",
      "  0.15611683 0.70916893 0.54604872]]\n",
      "\n",
      "Gradient Norm: 0.034792574478353495\n",
      "\n",
      "Gradient Matrix: [[ 4.14331104e-03 -1.31102875e-02 -9.47821273e-03 -1.06048314e-02\n",
      "  -1.16844837e-02  2.29623667e-03 -2.63643035e-03 -1.40859443e-02\n",
      "  -5.13892073e-03]\n",
      " [-4.53389101e-03 -1.00918390e-02 -1.09266060e-02 -4.05922042e-03\n",
      "   2.61095550e-05 -1.05412013e-02 -6.96826512e-03 -4.23085104e-03\n",
      "   3.12423594e-03]]\n",
      "\n",
      "Model Loss: 34.265485208741865\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 71\n",
      "Learning Rate: 0.05\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.994749929754732, 0.005250070245268023]\n",
      "\n",
      "Weight Matrix: [[0.60328635 0.1390057  0.16583824 0.12118238 0.12711978 0.55568258\n",
      "  0.3666025  0.1725608  0.14922735]\n",
      " [0.48387808 0.14247337 0.06538643 0.57016939 0.13962745 0.19124228\n",
      "  0.15338627 0.70452222 0.53604109]]\n",
      "\n",
      "Gradient Norm: 0.03478295500450984\n",
      "\n",
      "Gradient Matrix: [[ 0.00345308 -0.0127475  -0.00926916 -0.0098295  -0.01124185  0.00060629\n",
      "  -0.00298692 -0.01287818 -0.00571379]\n",
      " [-0.00512932 -0.01075159 -0.01174477 -0.00445969 -0.00072447 -0.01127181\n",
      "  -0.00767753 -0.00467714  0.00325544]]\n",
      "\n",
      "Model Loss: 34.265338168486636\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 72\n",
      "Learning Rate: 5.960464477539063e-09\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9945130901485278, 0.00548690985147208]\n",
      "\n",
      "Weight Matrix: [[0.59206181 0.14133439 0.16534115 0.12200929 0.12846239 0.54496124\n",
      "  0.36061072 0.17631017 0.14507375]\n",
      " [0.47956082 0.14225218 0.06567498 0.5656208  0.13176344 0.19124184\n",
      "  0.1507685  0.70006746 0.52644688]]\n",
      "\n",
      "Gradient Norm: 0.03491457420508493\n",
      "\n",
      "Gradient Matrix: [[ 0.00309315 -0.01262346 -0.009211   -0.00950368 -0.0110639  -0.00021167\n",
      "  -0.00317515 -0.01235899 -0.00599862]\n",
      " [-0.00539855 -0.01104776 -0.01211407 -0.00463603 -0.00106849 -0.01159412\n",
      "  -0.00799671 -0.00487306  0.00331382]]\n",
      "\n",
      "Model Loss: 34.27774101687359\n",
      "==============================================================================================================================\n",
      "\n",
      "Iteration: 73\n",
      "Learning Rate: 5.960464477539063e-09\n",
      "L1_Penalty Term: 0.01\n",
      "L2_Penalty Term: 0.001\n",
      "Posterior Cache First Sample: [0.9945130901485278, 0.00548690985147208]\n",
      "\n",
      "Weight Matrix: [[0.59206181 0.14133439 0.16534115 0.12200929 0.12846239 0.54496124\n",
      "  0.36061072 0.17631017 0.14507375]\n",
      " [0.47956082 0.14225218 0.06567498 0.5656208  0.13176344 0.19124184\n",
      "  0.1507685  0.70006746 0.52644688]]\n",
      "\n",
      "Gradient Norm: 0.03491457420508493\n",
      "\n",
      "Gradient Matrix: [[ 0.00309315 -0.01262346 -0.009211   -0.00950368 -0.0110639  -0.00021167\n",
      "  -0.00317515 -0.01235899 -0.00599862]\n",
      " [-0.00539855 -0.01104776 -0.01211407 -0.00463603 -0.00106849 -0.01159412\n",
      "  -0.00799671 -0.00487306  0.00331382]]\n",
      "\n",
      "Model Loss: 34.27774101687359\n",
      "==============================================================================================================================\n",
      "\n",
      "_Optimization Successful_\n"
     ]
    }
   ],
   "source": [
    "import BARISTA\n",
    "\n",
    "barista = BARISTA.BARISTA()\n",
    "barista.fit(training_samples = X_train, training_labels = y_train, scheme = 'FISTA', \n",
    "                    learning_rate = 0.1, convergence_constant= 1e-6, max_iterations = 5000, \n",
    "                    l1_penalty = 0.01, l2_penalty = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification Performance**\n",
    "\n",
    "Now that the data has been fit, we can classify the testing instances. We also provide an accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.9657142857142857\n"
     ]
    }
   ],
   "source": [
    "barista.predict(X_test, y_test)\n",
    "print(\"Testing Accuracy:\", barista.accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8-kernel",
   "language": "python",
   "name": "python3.8-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
